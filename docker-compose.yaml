version: "3.9"
x-clickhouse-credentials: &clickhouse-credentials
  CLICKHOUSE_USER: dittofeed
  CLICKHOUSE_PASSWORD: password
x-backend-app-env: &backend-app-env
  <<: *clickhouse-credentials
  NODE_ENV: development
  DATABASE_URL: "postgresql://postgres:password@postgres:5432/dittofeed?connect_timeout=60"
  KAFKA_BROKERS: "kafka:29092"
  CLICKHOUSE_HOST: "http://clickhouse-server:8123"
  TEMPORAL_ADDRESS: "temporal:7233"
  API_HOST: "0.0.0.0"
  LOG_CONFIG: true
services:
  dashboard:
    build:
      context: .
      dockerfile: ./packages/dashboard/Dockerfile
    profiles: ["apps", "apps-api", "apps-worker"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - temporal
      - api
      - clickhouse-server
    environment:
      <<: *backend-app-env
    networks:
      - dittofeed-network-dev
  api:
    build:
      context: .
      dockerfile: ./packages/api/Dockerfile
    profiles: ["apps", "apps-dashboard", "apps-worker"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3001:3001"
    depends_on:
      - postgres
      - clickhouse-server
      - temporal
    environment:
      <<: *backend-app-env
      BOOTSTRAP_EVENTS: true
    networks:
      - dittofeed-network-dev
  worker:
    build:
      context: .
      dockerfile: ./packages/worker/Dockerfile
    profiles: ["apps", "apps-dashboard", "apps-api"]
    volumes:
      - ./mnt:/dittofeed-mnt
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
    networks:
      - dittofeed-network-dev
  lite:
    build:
      context: .
      dockerfile: ./packages/lite/Dockerfile
    profiles: ["apps-lite"]
    volumes:
      - ./mnt:/dittofeed-mnt
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
      DASHBOARD_URL: "http://localhost:3000"
      DASHBOARD_API_BASE: "http://localhost:3000"
    networks:
      - dittofeed-network-dev
  admin-cli:
    build:
      context: .
      dockerfile: ./packages/admin-cli/Dockerfile
    entrypoint: []
    profiles: ["apps"]
    command: tail -f /dev/null
    tty: true
    depends_on:
      - postgres
      - temporal
      - clickhouse-server
    environment:
      <<: *backend-app-env
    networks:
      - dittofeed-network-dev
  temporal:
    container_name: temporal
    depends_on:
      - postgres
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PWD=password
      - POSTGRES_SEEDS=postgres
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/dev.yaml
    image: temporalio/auto-setup:1.18.5
    labels:
      kompose.volume.type: configMap
    networks:
      - dittofeed-network-dev
    ports:
      - 7233:7233
    volumes:
      - ./packages/backend-lib/temporal-dynamicconfig:/etc/temporal/config/dynamicconfig
  postgres:
    image: "postgres:15"
    restart: always
    environment:
      POSTGRES_PASSWORD: password
      POSTGRES_DB: dittofeed
      POSTGRES_USER: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres:/var/lib/postgresql/data
    networks:
      - dittofeed-network-dev
  kafka:
    image: redpandadata/redpanda:v23.1.1
    profiles: ["kafka"]
    ports:
      - 9092:9092
      - 18081:18081
      - 18082:18082
      - 19644:9644
    command:
      - redpanda
      - start
      - --kafka-addr internal://0.0.0.0:29092,external://0.0.0.0:9092
      # Address the broker advertises to clients that connect to the Kafka API.
      # Use the internal addresses to connect to the Redpanda brokers'
      # from inside the same Docker network.
      # Use the external addresses to connect to the Redpanda brokers'
      # from outside the Docker network.
      - --advertise-kafka-addr internal://kafka:29092,external://localhost:9092
      - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
      # Address the broker advertises to clients that connect to the HTTP Proxy.
      - --advertise-pandaproxy-addr internal://kafka:8082,external://localhost:18082
      - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
      # Redpanda brokers use the RPC API to communicate with eachother internally.
      - --rpc-addr kafka:33145
      - --advertise-rpc-addr kafka:33145
      # Tells Seastar (the framework Redpanda uses under the hood) to use 1 core on the system.
      - --smp 1
      # The amount of memory to make available to Redpanda.
      - --memory 1G
      # Mode dev-container uses well-known configuration properties for development in containers.
      - --mode dev-container
      # enable logs for debugging.
      - --default-log-level=debug
    volumes:
      - kafka:/var/lib/redpanda/data
    networks:
      - dittofeed-network-dev
  clickhouse-server:
    image: clickhouse/clickhouse-server:23.8.8.20-alpine
    ports:
      - "8123:8123"
      - "9000:9000"
      - "9009:9009"
    environment:
      <<: *clickhouse-credentials
    volumes:
      - ./packages/backend-lib/clickhouse_config.dev.xml:/etc/clickhouse-server/config.xml
      - clickhouse_lib:/var/lib/clickhouse
      - clickhouse_log:/var/log/clickhouse-server
    networks:
      - dittofeed-network-dev
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    profiles: ["otel"]
    command: ["--config", "/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - 1888:1888 # pprof extension
      - 8888:8888 # Prometheus metrics exposed by the collector
      - 8889:8889 # Prometheus exporter metrics
      - 13133:13133 # health_check extension
      - 4317:4317 # OTLP gRPC receiver
      - 4318:4318 # OTLP http receiver
      - 55679:55679 # zpages extension
    networks:
      - dittofeed-network-dev
  zipkin:
    image: openzipkin/zipkin
    profiles: ["otel"]
    container_name: zipkin
    ports:
      - 9411:9411
    networks:
      - dittofeed-network-dev
  grafana:
    image: grafana/grafana
    profiles: ["otel"]
    ports:
      - "9091:3000"
    volumes:
      - ./grafana-datasource-prometheus.yaml:/etc/grafana/provisioning/datasources/grafana-datasource-prometheus.yaml
      - grafana-storage:/var/lib/grafana
    networks:
      - dittofeed-network-dev
  prometheus:
    image: prom/prometheus
    profiles: ["otel"]
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml
      - prometheus-storage:/prometheus
    networks:
      - dittofeed-network-dev
  mail-server:
    profiles: ["smtp"]
    image: mailhog/mailhog
    ports:
      - "1025:1025" # SMTP server
      - "8025:8025" # Web interface
  # Note that minio is only used for local development. In production, use any S3-compatible storage.
  blob-storage:
    image: minio/minio
    profiles: ["blob-storage"]
    ports:
      - "9010:9000"
      - "9011:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
    volumes:
      - blob-storage:/data
    command: server --console-address ":9001" /data

volumes:
  postgres:
  kafka:
  clickhouse_lib:
  clickhouse_log:
  grafana-storage:
  prometheus-storage:
  blob-storage:

networks:
  dittofeed-network-dev:
    driver: bridge
    name: dittofeed-network-dev
