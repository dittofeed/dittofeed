# Events and Delivery Search Optimization

## Background

I have a table with user events. These tables are held in ClickHouse. The data is modeled as a typical CDP, like e.g. segment.io's, with `identify` and `track` events.

The structure of these tables are represented in `packages/backend-lib/src/userEvents/clickhouse.ts`, with the critical table being defined as follows:

```sql
CREATE TABLE IF NOT EXISTS user_events_v2 (
  event_type Enum(
    'identify' = 1,
    'track' = 2,
    'page' = 3,
    'screen' = 4,
    'group' = 5,
    'alias' = 6
  ) DEFAULT JSONExtract(
    message_raw,
    'type',
    'Enum(\\'identify\\' = 1, \\'track\\' = 2, \\'page\\' = 3, \\'screen\\' = 4, \\'group\\' = 5, \\'alias\\' = 6)'
  ),
  event String DEFAULT JSONExtract(
    message_raw,
    'event',
    'String'
  ),
  event_time DateTime64 DEFAULT assumeNotNull(
    parseDateTime64BestEffortOrNull(
      JSONExtractString(message_raw, 'timestamp'),
      3
    )
  ),
  message_id String,
  user_id String DEFAULT JSONExtract(
    message_raw,
    'userId',
    'String'
  ),
  anonymous_id String DEFAULT JSONExtract(
    message_raw,
    'anonymousId',
    'String'
  ),
  user_or_anonymous_id String DEFAULT assumeNotNull(
    coalesce(
      JSONExtract(message_raw, 'userId', 'Nullable(String)'),
      JSONExtract(message_raw, 'anonymousId', 'Nullable(String)')
    )
  ),
  properties String DEFAULT assumeNotNull(
    coalesce(
      JSONExtract(message_raw, 'traits', 'Nullable(String)'),
      JSONExtract(message_raw, 'properties', 'Nullable(String)')
    )
  ),
  processing_time DateTime64(3) DEFAULT now64(3),
  server_time DateTime64(3),
  message_raw String,
  workspace_id String,
  INDEX message_id_idx message_id TYPE minmax GRANULARITY 4
)
ENGINE = MergeTree()
ORDER BY (
  workspace_id,
  processing_time,
  user_or_anonymous_id,
  event_time,
  message_id
);
```

As you can see, the `properties` field is a JSON string, which duplicates the data held in the `message_raw` field.

## The Problem

The problem we have at hand is to optimize the following functions:

- `findManyEventsWithCount` in `packages/backend-lib/src/userEvents.ts`
- `searchDeliveries` in `packages/backend-lib/src/deliveries.ts`

Note that "deliveries" are essentially an abstracton over user events. They are defined by `DFInternalMessageSent` events whose statuses are optionally updated by subsequent status update events.

The reason these functions are inefficient today is that that we frequently need to filter events, or derived deliveries, by properties. Examples of such properties are:

- `templateId`
- `broadcastId`
- `journeyId`

These properties are stored in the `properties` field of the `user_events_v2` table, for many events.

However, when workspaces contain many large events within a short time period, simply parsing the JSON in order to filter by these properties is CPU bound and is too slow.

## Analysis of Current Implementation

After analyzing the codebase, I've identified the following performance bottlenecks:

### Current Issues
1. **JSON Parsing at Query Time**: Both `findManyEventsWithCount` and `searchDeliveries` use `JSONExtract` functions to parse the `properties` field during query execution
2. **Frequently Extracted Fields**: The most commonly extracted properties across the codebase are:
   - `templateId` - Used for filtering messages by template
   - `broadcastId` - Used for filtering broadcast messages
   - `journeyId` - Used for filtering journey-based messages
   - `triggeringMessageId` - Used for delivery tracking
   - `variant.type` (channel) - Used for filtering by channel type
   - `variant.to` and `variant.from` - Used for delivery searches

3. **Complex Aggregations**: The `searchDeliveries` function performs complex GROUP BY operations after parsing JSON, which compounds the CPU cost

### Critical Insight: Field Sparsity
**Only internal events contain these properties**. Internal events are `track` events generated by the application itself, distinguished by event names starting with "DF" prefix (e.g., `DFInternalMessageSent`, `DFEmailDelivered`, etc.). This means:
- Regular user-submitted events (`identify`, `page`, `screen`, and non-DF `track` events) will NOT have these fields
- Only `track` events with event names starting with "DF" contain `templateId`, `broadcastId`, `journeyId`, etc.
- The ratio of internal events to total events will vary significantly by workspace usage patterns
- Currently, we're parsing JSON for ALL events even though only DF-prefixed track events contain these fields
- This wastes significant CPU on empty extractions for the majority of events

## Proposed Solutions

### Solution 1: Add Conditional Materialized Columns 

Add new columns with conditional DEFAULT expressions that only extract for internal events:

```sql
ALTER TABLE user_events_v2 
ADD COLUMN template_id String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSONExtractString(properties, 'templateId'), ''),
ADD COLUMN broadcast_id String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSONExtractString(properties, 'broadcastId'), ''),
ADD COLUMN journey_id String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSONExtractString(properties, 'journeyId'), ''),
ADD COLUMN triggering_message_id String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSONExtractString(properties, 'triggeringMessageId'), ''),
ADD COLUMN channel_type String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSON_VALUE(properties, '$.variant.type'), ''),
ADD COLUMN delivery_to String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSON_VALUE(properties, '$.variant.to'), ''),
ADD COLUMN delivery_from String DEFAULT if(event_type = 'track' AND startsWith(event, 'DF'), JSON_VALUE(properties, '$.variant.from'), '');
```

**Advantages:**
- Only parses JSON for internal events (not user events)
- Minimal code changes required
- No data duplication beyond the column storage

**Disadvantages:**
- Still adds columns to main table with mostly empty values
- Increases storage for all rows even though most are empty
- Not optimal for such sparse data

### Solution 2: Create a Materialized View for Internal Events (RECOMMENDED)

Create a specialized materialized view that only includes internal events:

```sql
CREATE MATERIALIZED VIEW internal_events_mv
ENGINE = MergeTree()
ORDER BY (workspace_id, processing_time, user_or_anonymous_id, event, message_id)
AS SELECT
  workspace_id,
  user_or_anonymous_id,
  user_id,
  anonymous_id,
  message_id,
  event,
  event_type,
  event_time,
  processing_time,
  properties,
  JSONExtractString(properties, 'templateId') as template_id,
  JSONExtractString(properties, 'broadcastId') as broadcast_id,
  JSONExtractString(properties, 'journeyId') as journey_id,
  JSONExtractString(properties, 'triggeringMessageId') as triggering_message_id,
  JSON_VALUE(properties, '$.variant.type') as channel_type,
  JSON_VALUE(properties, '$.variant.to') as delivery_to,
  JSON_VALUE(properties, '$.variant.from') as delivery_from,
  JSONExtractString(properties, 'messageId') as origin_message_id
FROM user_events_v2
WHERE event_type = 'track' AND startsWith(event, 'DF');  -- Only internal (DF-prefixed) track events

-- Add indexes on the materialized view
ALTER TABLE internal_events_mv
ADD INDEX idx_template_id template_id TYPE bloom_filter(0.01) GRANULARITY 4,
ADD INDEX idx_broadcast_id broadcast_id TYPE bloom_filter(0.01) GRANULARITY 4,
ADD INDEX idx_journey_id journey_id TYPE bloom_filter(0.01) GRANULARITY 4;
```

**Advantages:**
- Only processes internal events - significant reduction in data volume compared to main table
- Pre-parsed JSON fields eliminate runtime parsing completely
- Can be optimized with different sort order and indexes specific to delivery queries
- Main table remains unchanged - no impact on write performance for user events
- Much smaller storage footprint than Solution 1 (only stores internal events)

**Disadvantages:**
- Requires code changes to query the new view for delivery/internal event queries
- Slight storage duplication for internal events only
- Need to maintain consistency between queries on main table vs materialized view

### Solution 3: Hybrid Approach with Projection

Use ClickHouse projections to create an alternative storage layout:

```sql
ALTER TABLE user_events_v2 ADD PROJECTION delivery_projection (
  SELECT 
    workspace_id,
    user_or_anonymous_id,
    message_id,
    event,
    event_time,
    processing_time,
    JSONExtractString(properties, 'templateId') as template_id,
    JSONExtractString(properties, 'broadcastId') as broadcast_id,
    JSONExtractString(properties, 'journeyId') as journey_id,
    properties
  ORDER BY workspace_id, template_id, broadcast_id, journey_id, processing_time
);
```

**Advantages:**
- ClickHouse automatically chooses the best projection for queries
- No code changes required
- Data consistency guaranteed

**Disadvantages:**
- Increases storage requirements
- Limited flexibility in projection definition
- May not be used for all query patterns

## Implementation Recommendations

### Recommended Approach: Solution 2 - Materialized View for Internal Events

Given that these properties only exist in internal events, **Solution 2 (Materialized View)** is now the recommended approach. This avoids the inefficiency of adding sparse columns to the main table.

#### Phase 1: Create the Materialized View
1. Create `internal_events_mv` with pre-parsed JSON fields
2. The view will automatically populate with new internal events going forward
3. Backfill historical data by recreating the view with `POPULATE` keyword if needed

#### Phase 2: Update Query Logic
1. Modify `searchDeliveries` to query `internal_events_mv` instead of `user_events_v2`
2. Update `findManyEventsWithCount` to use `internal_events_mv` when filtering by internal event properties
3. Implement query routing logic: 
   - Use `internal_events_mv` for queries filtering on templateId, broadcastId, journeyId
   - Use `user_events_v2` for general event queries

#### Phase 3: Monitor and Optimize
1. Add bloom filter indexes on frequently filtered columns
2. Consider adjusting the sort order based on actual query patterns
3. Monitor query performance improvements

### Performance Impact Analysis

#### Expected Improvements
- **Query Performance**: Significant improvement for queries filtering on internal event properties
- **CPU Usage**: Eliminates JSON parsing at query time for internal event queries
- **Memory Usage**: Reduced memory pressure from not parsing JSON during queries

#### Storage Impact
- **Additional Storage**: Only for internal events (actual percentage depends on workspace usage)
- **Index Storage**: Minimal - bloom filters are space-efficient
- **Trade-off**: Storage duplication only for internal events vs. runtime CPU savings

### Measuring Impact

Before implementation, it would be valuable to measure in production:
- The ratio of internal events to total events across different workspaces
- The frequency of queries that filter on these internal event properties
- Current CPU usage patterns during JSON extraction

This data will help validate the expected performance improvements.

### Alternative Considerations

If the materialized view approach doesn't provide sufficient performance improvements, consider:

1. **Partial Materialized View**: Create a materialized view only for the most recent data (e.g., last 30 days)
2. **Tiered Storage**: Move older events to a different table with a different schema
3. **Distributed Processing**: Use ClickHouse's distributed tables for horizontal scaling
4. **Aggregated View**: For `searchDeliveries`, consider a pre-aggregated materialized view that groups events by messageId

## Migration Strategy

### Step-by-Step Migration Plan

1. **Testing Environment**
   - Implement changes in a test environment first
   - Benchmark query performance before and after changes
   - Validate data consistency

2. **Production Rollout**
   - Add columns during low-traffic periods
   - Backfill data in batches to avoid system overload
   - Monitor system metrics during migration

3. **Code Updates**
   - Update queries to use new columns with feature flags
   - Gradually roll out to a percentage of queries
   - Monitor for any issues or performance regressions

### Rollback Plan

If issues arise:
1. Queries can immediately revert to using JSONExtract
2. New columns can be dropped without data loss
3. The original `properties` field remains unchanged

## Best Practices and ClickHouse Recommendations

### ClickHouse Best Practices Applied

1. **Compute on Write**: Pre-computing values at insert time is more efficient than compute-on-read
2. **Skip Indexes**: Bloom filters are ideal for columns with moderate cardinality (like templateId, journeyId)
3. **Column Types**: Using `LowCardinality(String)` for columns with limited unique values can improve compression
4. **DEFAULT vs MATERIALIZED**: DEFAULT columns are preferred as they don't take space for NULL values

### Monitoring and Optimization

After implementation, monitor:
- Query execution time via `system.query_log`
- Index effectiveness via `system.data_skipping_indices`
- Storage usage via `system.parts`
- CPU and memory usage during peak query times

## Query Optimization Examples

### Before Optimization (Current State)

```sql
-- findManyEventsWithCount current query (simplified)
SELECT
  *,
  if(
    properties != '',
    JSONExtract(properties, 'Tuple(broadcastId String, journeyId String)'),
    CAST(('', ''), 'Tuple(broadcastId String, journeyId String)')
  ) AS parsed_properties
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND JSONExtractString(properties, 'broadcastId') = 'broadcast456'  -- CPU intensive
  AND JSONExtractString(properties, 'journeyId') = 'journey789'      -- CPU intensive
```

### After Optimization

```sql
-- findManyEventsWithCount optimized query
SELECT
  *,
  broadcast_id,
  journey_id
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND broadcast_id = 'broadcast456'  -- Direct column access with bloom filter
  AND journey_id = 'journey789'      -- Direct column access with bloom filter
```

### Delivery Search Optimization

```sql
-- searchDeliveries before (simplified inner query)
SELECT
  ...,
  JSONExtractString(properties, 'templateId') as template_id,
  JSONExtractString(properties, 'broadcastId') as broadcast_id,
  JSON_VALUE(properties, '$.variant.type') as channel_type
FROM user_events_v2
WHERE
  event IN [...]
  AND JSONExtractString(properties, 'broadcastId') = 'broadcast456'  -- Scans all rows

-- searchDeliveries after
SELECT
  ...,
  template_id,      -- Direct column access
  broadcast_id,     -- Direct column access  
  channel_type      -- Direct column access
FROM user_events_v2
WHERE
  event IN [...]
  AND broadcast_id = 'broadcast456'  -- Uses bloom filter index
```

## High Level Goals

- The number 1 most important goal is to make the `searchDeliveries` and `findManyEventsWithCount` functions fast, by improving their query CPU usage.
- The table `user_events_v2` is the most frequently written to table in the database, so writes should not be made overly expensive.
- Solutions should be prioritized based on how conventional they are based on ClickHouse community recommendations. Frequent consultation of the web for the purpose of establishing best practices is encouraged.
