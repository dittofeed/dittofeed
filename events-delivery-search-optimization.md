# Events and Delivery Search Optimization

## Background

I have a table with user events. These tables are held in ClickHouse. The data is modeled as a typical CDP, like e.g. segment.io's, with `identify` and `track` events.

The structure of these tables are represented in `packages/backend-lib/src/userEvents/clickhouse.ts`, with the critical table being defined as follows:

```sql
CREATE TABLE IF NOT EXISTS user_events_v2 (
  event_type Enum(
    'identify' = 1,
    'track' = 2,
    'page' = 3,
    'screen' = 4,
    'group' = 5,
    'alias' = 6
  ) DEFAULT JSONExtract(
    message_raw,
    'type',
    'Enum(\\'identify\\' = 1, \\'track\\' = 2, \\'page\\' = 3, \\'screen\\' = 4, \\'group\\' = 5, \\'alias\\' = 6)'
  ),
  event String DEFAULT JSONExtract(
    message_raw,
    'event',
    'String'
  ),
  event_time DateTime64 DEFAULT assumeNotNull(
    parseDateTime64BestEffortOrNull(
      JSONExtractString(message_raw, 'timestamp'),
      3
    )
  ),
  message_id String,
  user_id String DEFAULT JSONExtract(
    message_raw,
    'userId',
    'String'
  ),
  anonymous_id String DEFAULT JSONExtract(
    message_raw,
    'anonymousId',
    'String'
  ),
  user_or_anonymous_id String DEFAULT assumeNotNull(
    coalesce(
      JSONExtract(message_raw, 'userId', 'Nullable(String)'),
      JSONExtract(message_raw, 'anonymousId', 'Nullable(String)')
    )
  ),
  properties String DEFAULT assumeNotNull(
    coalesce(
      JSONExtract(message_raw, 'traits', 'Nullable(String)'),
      JSONExtract(message_raw, 'properties', 'Nullable(String)')
    )
  ),
  processing_time DateTime64(3) DEFAULT now64(3),
  server_time DateTime64(3),
  message_raw String,
  workspace_id String,
  INDEX message_id_idx message_id TYPE minmax GRANULARITY 4
)
ENGINE = MergeTree()
ORDER BY (
  workspace_id,
  processing_time,
  user_or_anonymous_id,
  event_time,
  message_id
);
```

As you can see, the `properties` field is a JSON string, which duplicates the data held in the `message_raw` field.

## The Problem

The problem we have at hand is to optimize the following functions:

- `findManyEventsWithCount` in `packages/backend-lib/src/userEvents.ts`
- `searchDeliveries` in `packages/backend-lib/src/deliveries.ts`

Note that "deliveries" are essentially an abstracton over user events. They are defined by `DFInternalMessageSent` events whose statuses are optionally updated by subsequent status update events.

The reason these functions are inefficient today is that that we frequently need to filter events, or derived deliveries, by properties. Examples of such properties are:

- `templateId`
- `broadcastId`
- `journeyId`

These properties are stored in the `properties` field of the `user_events_v2` table, for many events.

However, when workspaces contain many large events within a short time period, simply parsing the JSON in order to filter by these properties is CPU bound and is too slow.

## Analysis of Current Implementation

After analyzing the codebase, I've identified the following performance bottlenecks:

### Current Issues
1. **JSON Parsing at Query Time**: Both `findManyEventsWithCount` and `searchDeliveries` use `JSONExtract` functions to parse the `properties` field during query execution
2. **Frequently Extracted Fields**: The most commonly extracted properties across the codebase are:
   - `templateId` - Used for filtering messages by template
   - `broadcastId` - Used for filtering broadcast messages
   - `journeyId` - Used for filtering journey-based messages
   - `triggeringMessageId` - Used for delivery tracking
   - `variant.type` (channel) - Used for filtering by channel type
   - `variant.to` and `variant.from` - Used for delivery searches

3. **Complex Aggregations**: The `searchDeliveries` function performs complex GROUP BY operations after parsing JSON, which compounds the CPU cost

### Critical Insight: Field Sparsity
**Only internal events contain these properties**. Internal events are `track` events generated by the application itself, distinguished by event names starting with "DF" prefix (e.g., `DFInternalMessageSent`, `DFEmailDelivered`, etc.). This means:
- Regular user-submitted events (`identify`, `page`, `screen`, and non-DF `track` events) will NOT have these fields
- Only `track` events with event names starting with "DF" contain `templateId`, `broadcastId`, `journeyId`, etc.
- The ratio of internal events to total events will vary significantly by workspace usage patterns
- Currently, we're parsing JSON for ALL events even though only DF-prefixed track events contain these fields
- This wastes significant CPU on empty extractions for the majority of events

## Proposed Solution: Materialized View for Internal Events

Create a specialized table and materialized view for internal events:

```sql
-- Step 1: Create the target table to store internal events with parsed fields
CREATE TABLE IF NOT EXISTS internal_events (
  workspace_id String,
  user_or_anonymous_id String,
  user_id String,
  anonymous_id String,
  message_id String,
  event String,
  processing_time DateTime64(3),
  properties String,
  template_id String,
  broadcast_id String,
  journey_id String,
  triggering_message_id String,
  channel_type String,
  delivery_to String,
  delivery_from String,
  origin_message_id String,
  INDEX idx_template_id template_id TYPE bloom_filter(0.01) GRANULARITY 4,
  INDEX idx_broadcast_id broadcast_id TYPE bloom_filter(0.01) GRANULARITY 4,
  INDEX idx_journey_id journey_id TYPE bloom_filter(0.01) GRANULARITY 4
)
ENGINE = MergeTree()
ORDER BY (workspace_id, processing_time, event, user_or_anonymous_id, message_id);

-- Step 2: Create the materialized view that populates the table
CREATE MATERIALIZED VIEW IF NOT EXISTS internal_events_mv
TO internal_events
AS SELECT
  workspace_id,
  user_or_anonymous_id,
  user_id,
  anonymous_id,
  message_id,
  event,
  processing_time,
  properties,
  JSONExtractString(properties, 'templateId') as template_id,
  JSONExtractString(properties, 'broadcastId') as broadcast_id,
  JSONExtractString(properties, 'journeyId') as journey_id,
  JSONExtractString(properties, 'triggeringMessageId') as triggering_message_id,
  JSONExtractString(properties, 'variant', 'type') as channel_type,
  JSONExtractString(properties, 'variant', 'to') as delivery_to,
  JSONExtractString(properties, 'variant', 'from') as delivery_from,
  JSONExtractString(properties, 'messageId') as origin_message_id
FROM user_events_v2
WHERE event_type = 'track' AND startsWith(event, 'DF');  -- Only internal (DF-prefixed) track events
```

**Advantages:**
- Only processes internal events - significant reduction in data volume compared to main table
- Pre-parsed JSON fields eliminate runtime parsing completely
- Can be optimized with different sort order and indexes specific to delivery queries
- Main table remains unchanged - no impact on write performance for user events
- Much smaller storage footprint (only stores internal events, not all events)
- Materialized view acts as an automatic ETL pipeline, parsing JSON once at insert time

**Trade-offs:**
- Requires code changes to query the new `internal_events` table for delivery/internal event queries
- Storage duplication for internal events (stored in both `user_events_v2` and `internal_events`)
- Need to maintain query routing logic between the two tables
- Materialized view adds slight overhead to inserts of internal events (but only internal events)

## Implementation Strategy

#### Phase 1: Create the Table and Materialized View

This phase will involve modifying the `packages/backend-lib/src/userEvents/clickhouse.ts` file.

1. Create the `internal_events` table with pre-parsed field columns
2. Create `internal_events_mv` materialized view that writes TO the table
3. The view will automatically populate the table with new internal events going forward
4. For historical data, you can either:
   - Recreate the view with `POPULATE` keyword (be careful with large datasets)
   - Manually insert historical data with a one-time query

#### Phase 2: Update Query Logic

##### 2.1 Sample Query Transformations for `searchDeliveries`

**Current Query (simplified from deliveries.ts:534-563):**
```sql
-- Inner query that extracts JSON at query time
SELECT
  argMax(event, event_time) last_event,
  anyIf(properties, properties != '') properties,
  max(event_time) updated_at,
  min(event_time) sent_at,
  user_or_anonymous_id,
  origin_message_id,
  any(triggering_message_id) as triggering_message_id,
  workspace_id
FROM (
  SELECT
    workspace_id,
    user_or_anonymous_id,
    if(event = 'DFInternalMessageSent', properties, '') properties,
    event,
    event_time,
    -- CPU-intensive JSON parsing happens here for ALL rows before filtering
    if(
      properties != '',
      JSONExtract(properties, 'Tuple(messageId String, triggeringMessageId String, broadcastId String, journeyId String, templateId String)'),
      CAST(('', '', '', '', ''), 'Tuple(messageId String, triggeringMessageId String, broadcastId String, journeyId String, templateId String)')
    ) AS parsed_properties,
    if(event = 'DFInternalMessageSent', message_id, parsed_properties.messageId) origin_message_id
  FROM user_events_v2
  WHERE
    event IN ['DFInternalMessageSent', 'DFEmailDelivered', 'DFSmsSent', ...]
    AND workspace_id = 'workspace123'
    -- Additional JSON parsing for channel filtering
    AND JSON_VALUE(properties, '$.variant.type') = 'email'
)
GROUP BY workspace_id, user_or_anonymous_id, origin_message_id
HAVING
  -- Filtering happens AFTER the expensive JSON parsing
  parsed_properties.broadcastId = 'broadcast456'
  AND parsed_properties.journeyId = 'journey789'
```

**New Query using `internal_events` table (two-step pattern):**
```sql
-- Optimized query using nested subquery pattern
SELECT
  argMax(event, event_time) last_event,
  anyIf(properties, properties != '') properties,
  max(event_time) updated_at,
  min(event_time) sent_at,
  user_or_anonymous_id,
  origin_message_id,
  any(triggering_message_id) as triggering_message_id,
  workspace_id,
  max(processing_time) as processing_time
FROM (
  SELECT
    workspace_id,
    user_or_anonymous_id,
    if(event = 'DFInternalMessageSent', properties, '') properties,
    event,
    event_time,
    processing_time,
    if(event = 'DFInternalMessageSent', message_id, JSONExtractString(properties, 'messageId')) origin_message_id,
    JSONExtractString(properties, 'triggeringMessageId') as triggering_message_id
  FROM user_events_v2
  WHERE
    workspace_id = 'workspace123'
    AND message_id IN (
      -- Nested query to internal_events for efficient filtering
      SELECT DISTINCT message_id
      FROM internal_events
      WHERE
        event IN ['DFInternalMessageSent', 'DFEmailDelivered', 'DFSmsSent', ...]
        AND workspace_id = 'workspace123'
        -- Direct column comparison with bloom filter indexes - no JSON parsing
        AND broadcast_id = 'broadcast456'
        AND journey_id = 'journey789'
        AND channel_type = 'email'
    )
)
GROUP BY workspace_id, user_or_anonymous_id, origin_message_id
ORDER BY processing_time DESC
```

##### 2.2 Sample Query Transformations for `findManyEventsWithCount`

**Current Query (simplified from userEvents.ts:441-466):**
```sql
-- Current implementation that checks for internal event properties
SELECT
  workspace_id,
  user_id,
  user_or_anonymous_id,
  event_time,
  message_id,
  event,
  event_type,
  processing_time,
  properties,
  -- Conditional JSON parsing based on whether filters are present
  if(
    properties != '',
    JSONExtract(properties, 'Tuple(broadcastId String, journeyId String)'),
    CAST(('', ''), 'Tuple(broadcastId String, journeyId String)')
  ) AS parsed_properties
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND processing_time >= '2024-01-01 00:00:00'
  AND processing_time <= '2024-01-31 23:59:59'
  -- JSON extraction in WHERE clause for filtering
  AND parsed_properties.broadcastId = 'broadcast456'
  AND parsed_properties.journeyId = 'journey789'
ORDER BY processing_time DESC
LIMIT 100
```

**New Query when internal event filters are present (two-step pattern):**
```sql
-- Optimized query using nested subquery pattern
SELECT
  workspace_id,
  user_id,
  user_or_anonymous_id,
  event_time,
  message_id,
  event,
  event_type,
  processing_time,
  properties
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND message_id IN (
    -- Nested query to internal_events for efficient filtering
    SELECT message_id
    FROM internal_events
    WHERE
      workspace_id = 'workspace123'
      AND processing_time >= '2024-01-01 00:00:00'
      AND processing_time <= '2024-01-31 23:59:59'
      -- Direct column comparison with bloom filter indexes
      AND broadcast_id = 'broadcast456'
      AND journey_id = 'journey789'
    ORDER BY processing_time DESC
    LIMIT 100
  )
ORDER BY processing_time DESC
```

**Query for non-internal events (unchanged):**
```sql
-- When NO internal event filters are present, continue using user_events_v2
SELECT
  workspace_id,
  user_id,
  user_or_anonymous_id,
  event_time,
  message_id,
  event,
  event_type,
  processing_time,
  properties
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND event_type = 'identify'  -- Example: non-internal event query
  AND user_id = 'user123'
ORDER BY processing_time DESC
LIMIT 100
```

##### 2.3 Key Design Decision: Two-Step Query Pattern

The optimized approach uses a two-step pattern:

1. **First step**: Use `internal_events` table to efficiently filter events based on pre-parsed fields (broadcastId, journeyId, templateId, etc.) and get the relevant message_ids
2. **Second step**: Use the filtered message_ids to fetch full event data from `user_events_v2`

This approach provides:
- **Performance**: JSON parsing only happens during materialized view insertion, not at query time
- **Completeness**: We still get all event fields from the main table (not just the extracted ones)
- **Efficiency**: The IN clause with message_ids is much faster than parsing JSON for all rows

**Query Routing Rule**: For delivery queries (`searchDeliveries`), we will ALWAYS use the `internal_events` table unconditionally, regardless of filter presence. This approach is justified because:
1. Delivery queries only care about internal (DF-prefixed) track events, which the `internal_events` table is pre-filtered for
2. The `internal_events` table has an optimized sort key `(workspace_id, processing_time, event, user_or_anonymous_id, message_id)` with `event` in a forward position, unlike the base `user_events_v2` table which does not include `event` in the sort key.
3. This eliminates the need for conditional query routing logic and ensures consistent performance for all delivery queries
4. Even when no internal event filters are present, querying the smaller, pre-filtered `internal_events` table will be faster than scanning the full `user_events_v2` table

Note: `event_time` and `processing_time` can differ significantly due to clock skew, network failures with retries, etc.

##### 2.4 Performance Comparison Queries

To validate the optimization, compare the performance of queries before and after:

```sql
-- Query to benchmark current approach (with JSON parsing)
EXPLAIN ESTIMATE
SELECT count()
FROM user_events_v2
WHERE
  event_type = 'track' 
  AND startsWith(event, 'DF')
  AND workspace_id = 'workspace123'
  AND JSONExtractString(properties, 'broadcastId') = 'broadcast456'
  AND JSONExtractString(properties, 'journeyId') = 'journey789';

-- Query to benchmark new approach (no JSON parsing)
EXPLAIN ESTIMATE
SELECT count()
FROM internal_events
WHERE
  workspace_id = 'workspace123'
  AND broadcast_id = 'broadcast456'
  AND journey_id = 'journey789';
```

Monitor actual query performance:
```sql
-- Track performance improvements
SELECT 
  query_kind,
  query,
  query_duration_ms,
  read_rows,
  read_bytes,
  memory_usage
FROM system.query_log
WHERE 
  event_date = today()
  AND type = 'QueryFinish'
  AND (
    query LIKE '%internal_events%'
    OR (query LIKE '%user_events_v2%' AND query LIKE '%JSONExtract%')
  )
ORDER BY event_time DESC
LIMIT 100;
```

#### Phase 2.5 Running Tests

```bash
LOG_LEVEL=debug yarn jest packages/backend-lib/src/userEvents.test.ts
LOG_LEVEL=debug yarn jest packages/backend-lib/src/deliveries.test.ts
```

You can also add debug logging to the `searchDeliveries` and `findManyEventsWithCount` functions:

```typescript
logger().debug({ key: value }, "message")
```

### Phase 3. QA in Production

1. Generate isolated queries to create new table and view.
2. Generate isolated query to backfill the new table with historical data.
3. Write two scripts in `packages/admin-cli/src/commandDefinitions.ts` to generate query strings from dynamic parameters, that I can use to test the performance of queries. This may require refactoring of the existing backend code into a new function for generating the query prior to executing it.
4. Modify this section of this document to add sample query generating commands of the form `yarn admin <command> <args>`.

Note that these commands should include the `dittofeed.` database name preceding the table names, unlike in production where the database name is omitted due to being set from the client.

#### 3.1 Sample Query Generating Commands

```bash
# FIXME
```

### Performance Impact Analysis

#### Expected Improvements
- **Query Performance**: Significant improvement for queries filtering on internal event properties
- **CPU Usage**: Eliminates JSON parsing at query time for internal event queries
- **Memory Usage**: Reduced memory pressure from not parsing JSON during queries

#### Storage Impact
- **Additional Storage**: Only for internal events (actual percentage depends on workspace usage)
- **Index Storage**: Minimal - bloom filters are space-efficient
- **Trade-off**: Storage duplication only for internal events vs. runtime CPU savings

### Measuring Impact

Before implementation, it would be valuable to measure in production:
- The ratio of internal events to total events across different workspaces
- The frequency of queries that filter on these internal event properties
- Current CPU usage patterns during JSON extraction

This data will help validate the expected performance improvements.

### Alternative Optimizations

If this approach doesn't provide sufficient performance improvements, consider:

1. **Partial Materialized View**: Create a view only for recent data (e.g., last 30 days) if most queries focus on recent events
2. **Pre-Aggregated View**: For `searchDeliveries`, create an additional view that pre-groups events by messageId to eliminate the GROUP BY at query time
3. **Tiered Storage**: Move older events to separate tables with different schemas or compression settings

## Migration Strategy

### Step-by-Step Migration Plan

1. **Testing Environment**
   - Create the `internal_events` table and materialized view in test environment
   - Validate that the materialized view correctly populates with internal events
   - Test query performance against the new table vs. original table

2. **Production Rollout**
   - Deploy the table and materialized view during low-traffic periods
   - Monitor that the materialized view is correctly processing new internal events
   - Consider manually backfilling historical data if needed

3. **Code Updates**
   - Update delivery/internal event queries to use `internal_events` table
   - Implement query routing logic with feature flags
   - Gradually roll out to a percentage of queries
   - Monitor for performance improvements and any issues

### Rollback Plan

If issues arise:
1. Queries can immediately revert to using `user_events_v2` table
2. Drop the materialized view and table without affecting the main table
3. No impact on existing functionality since `user_events_v2` remains unchanged

## Best Practices and ClickHouse Recommendations

### ClickHouse Best Practices Applied

1. **Compute on Write**: Pre-computing values at insert time is more efficient than compute-on-read
2. **Skip Indexes**: Bloom filters are ideal for columns with moderate cardinality (like templateId, journeyId)
3. **Materialized Views**: Used as ETL pipelines to transform data during inserts
4. **Targeted Processing**: Only process events that contain the fields of interest

### Monitoring and Optimization

After implementation, monitor:
- Query execution time via `system.query_log`
- Index effectiveness via `system.data_skipping_indices`
- Storage usage via `system.parts`
- CPU and memory usage during peak query times

## Query Optimization Examples

### Before Optimization (Current State)

```sql
-- findManyEventsWithCount current query (simplified)
SELECT
  *,
  if(
    properties != '',
    JSONExtract(properties, 'Tuple(broadcastId String, journeyId String)'),
    CAST(('', ''), 'Tuple(broadcastId String, journeyId String)')
  ) AS parsed_properties
FROM user_events_v2
WHERE
  workspace_id = 'workspace123'
  AND JSONExtractString(properties, 'broadcastId') = 'broadcast456'  -- CPU intensive
  AND JSONExtractString(properties, 'journeyId') = 'journey789'      -- CPU intensive
```

### After Optimization

```sql
-- findManyEventsWithCount optimized query (for internal events)
SELECT
  *,
  broadcast_id,
  journey_id
FROM internal_events
WHERE
  workspace_id = 'workspace123'
  AND broadcast_id = 'broadcast456'  -- Direct column access with bloom filter
  AND journey_id = 'journey789'      -- Direct column access with bloom filter
```

### Delivery Search Optimization

```sql
-- searchDeliveries before (simplified inner query)
SELECT
  ...,
  JSONExtractString(properties, 'templateId') as template_id,
  JSONExtractString(properties, 'broadcastId') as broadcast_id,
  JSON_VALUE(properties, '$.variant.type') as channel_type
FROM user_events_v2
WHERE
  event IN ['DFInternalMessageSent', 'DFEmailDelivered', ...]
  AND JSONExtractString(properties, 'broadcastId') = 'broadcast456'  -- Parses JSON for ALL rows

-- searchDeliveries after (using internal_events table)
SELECT
  ...,
  template_id,      -- Direct column access, no JSON parsing
  broadcast_id,     -- Direct column access, no JSON parsing
  channel_type      -- Direct column access, no JSON parsing
FROM internal_events
WHERE
  event IN ['DFInternalMessageSent', 'DFEmailDelivered', ...]
  AND broadcast_id = 'broadcast456'  -- Uses bloom filter index, no parsing
```

## High Level Goals

- The number 1 most important goal is to make the `searchDeliveries` and `findManyEventsWithCount` functions fast, by improving their query CPU usage.
- The table `user_events_v2` is the most frequently written to table in the database, so writes should not be made overly expensive.
- Solutions should be prioritized based on how conventional they are based on ClickHouse community recommendations. Frequent consultation of the web for the purpose of establishing best practices is encouraged.
